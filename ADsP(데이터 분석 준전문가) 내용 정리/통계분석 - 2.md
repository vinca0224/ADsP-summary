# 통계분석 - 2

---

- 회귀분석의 개념 학습
- 최적 회귀방정식을 통한 모델의 성능 개선방법
- 다차원 척도법
- 주성분분석
- 시계열 데이터의 특성과 분석방법

---

**회귀분석**은 하나 이상의 독립변수들이 종속변수에 얼마나 영향을 미치는지 추정하는 기법이다.

- 기본적으로 독립변수가 **연속형 변수일 때 사용**하며, 범주형 변수일 경우 파생변수로 변환하여 사용한다.
- 종속변수가 **범주형일 경우 로지스틱 회귀분석**을 사용한다.
- 변수들이 일정한 경향성을 띈다 → 변수들이 일정한 인과관계를 갖고있을 것이다.
    - 즉, 산점도를 봤을 때 일정한 추세선이 나타나면, 경향성을 가지거나 변수들 간에 인관관계가 존재할 것이다.

---

회귀분석의 가정

1. **선형성** : 독립변수와 종속변수가 선형적이어야 한다, 회귀분석 전 상관분석은 거의 필수
    - 예외적으로 2차함수 회귀선을 갖는 다항회귀분석은 선형성을 갖지않아도 됨
2. **독립성**
    - 단순회귀분석에서 잔차와 독립변수의 값이 서로 독립이여야 한다.
    - 다중회귀분석에서 독립변수 간 상관성이 없이 독립이어야 한다
3. **등분산성** : 분산이 같아 잔차들이 고르게 분포함
    - 만약 등분산성을 만족 못 할 경우 추세를 띠지 못하고 뭉친 모양으로 나타남
4. **정규성** : 잔차항이 정규분포의 형태를 띰

---

**단순선형회귀분석**

- 독립변수와 종속변수가 1개일 때 둘 사이의 인과관계 분석
- **최소제곱법 :** 오차를 제곱해 더한 값이 작을수록 이상적인 회귀추세선

---

회귀분석모형의 적합성

- 분산분석표

![https://wikidocs.net/images/page/73481/11_4.jpg](https://wikidocs.net/images/page/73481/11_4.jpg)

회귀모형의 통계적 유의성 검증은 F-검정을 통해 확인한다.

- F-검정은 분산차를 확인하는 용도로 사용되는데, **분산차가 크다**는 것은 **회귀모형에서 회귀계수가 크다**는 의미이다.
- 즉, F-값이 크다는 변수간 유의미한 인과관계가 존재한다고 볼 수 있다.
- F-값이 크면, F-값이 0에서 얼마나 가까운지 확률적으로 측정한 p값은 상대적으로 작아진다.

회귀계수의 유의성은 t-검정을 통해 확인가능하다.

- t-통계량은 회귀계수를 표준오차로 나눈 값으로, t-통계량이 크다는 것은 분모에 해당하는 표준오차가 작다고 볼 수 있다.
- 즉, t-통계량이 커지면 회귀계수가 커지고, 유의미한 인과관계라는 것을 알 수 있다.
- 그렇게 때문에 t-통계량이 커져도 p값은 작아진다.

---

회귀모형의 설명력이 좋다는 것은 회귀성에 밀접하게 분포한다는 의미이다.

- 결정계수 R^2가 1에 가까우면 데이터들이 회귀선에 밀접하게 분포한다
- 즉, 모형의 예측력이 높고 회귀모형이 주어진 자료를 잘 설명한다는 것이다.
- 결정계수를 구하는 공식은 다음과 같다.
    
    $$
    R^2 = \frac {SSR} {SST} = 1- \frac {SSE} { SST}
    $$
    
- 결정계수는 독립변수의 수가 많아질수록 증가하는 성질을 가진다. 즉, 종속변수에 영향을 주지않는 독립변수가 포함되도 결정계수가 커지는데, 이를 보완한 개념이 수정된 결정계수이다.
    
    ![https://blog.kakaocdn.net/dn/pZfq5/btqSIYJMtHP/t8ITVNAO5iAEwpC670X5Pk/img.jpg](https://blog.kakaocdn.net/dn/pZfq5/btqSIYJMtHP/t8ITVNAO5iAEwpC670X5Pk/img.jpg)
    

---

**다중선형회귀분석** : 독립변수가 2개 이상이고 종속변수가 하나일 때 사용가능한 회귀분석

**다중공선성**은 독립변간 간에 강한 상관관계가 나타나는 현상으로, 회귀분석의 가정인 독립성에 위배된다.

- 다중공선성은 독립변수 간 상관계수를 구하거나,  분산팽창요인(VIF)가 10이상일 경우 다중공선성이 있다고 판단할 수 있다.
    
    [https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FpgTOl%2FbtqCjeCbYNf%2FEP9MSBzh5qjO5MtmYOSgpK%2Fimg.png](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FpgTOl%2FbtqCjeCbYNf%2FEP9MSBzh5qjO5MtmYOSgpK%2Fimg.png)
    

다중공선성의 문제의 해결방법

- 변수 제거
- 변수의 차원 축소 : 변수 삭제가 아닌 데이터의 내재적 속성을 보존하면서 데이터를 축소하는 방법
    - 주성분 분석(PCA)
    - 선형판별분석(LDA)
    - t - 분포 확률적 임베딩(t-SNE)
    - 특이값 분배(SVD)

---

**최적 회귀방정식**은 가장 잘 설명할 수 있는 회귀식을 가질 수 있는 독립변수들을 선택하는 과정이다.

- **부분집합법(임베디드 기법)** : 모든 가능한 모델을 고려하여 가장 좋은 모델을 선정
- **단계적 변수선택법** : 일정한 단계를 거치면서 변수를 추가 또는 삭제

변수 선택에 사용되는 성능지표

- **벌점화 모델**
    - 회귀모형은 변수의 수가 증가할수록 편향은 작아지고 분산은 커지는 경향을 보이기 때문에, 변수의 수에 따라 **벌점(페널티)**를 주어 최적 회귀방전식을 도출
    - **AIC**(아카이케 정보 기준) : 변수의 수만큼 패널티를 줌, 표본이 커질 때는 부정확해짐
    - **BIC**(베이즈 정보 기준) : 변수의 개수가 많아 질 수록 AIC보다 더 큰 페널티를 줌
- 멜로우 CP : CP값은 [최소 자승법](https://darkpgmr.tistory.com/56)으로 사용하여 추정된 회귀모형의 적합성을 평가
    - cp값은 모든 변수가 포함되면 p값과 같아짐, cp값이 p값보다 작을 수록 좋은 모델

---

**단계적 변수 선택법**

- **전진선택법** : 독립변수 중 가장 많은 영향을 줄 것으로 판단되는 **변수부터 하나씩 추가**
    - 설명력이 가장 높은 설명변수(**p-value가 가장 작은 변수**)부터 시작해 점점 추가
    - **변수값이 조금만 변해도 결과에 큰 영향**을 미침
    - **상관계수의 절대값이 가장 큰 변수**에 대해 부분 F 검정으로 유의성을 검정하고 더이상 유의하지 않을 경우 해당 변수는 추가하지 않음
- 후진제거법 : 가장 적은 영향을 주는 변수부터 하나씩 제거
    - **상관계수의 절대값이 가장 작은 변수**에 대래 부분 F 검정 실시 후 가장 적은 영향을 주는 변수부터 하나씩 제거
    - 변수의 개수가 너무 많은 경우 적용하기 힘듬
- 단계별 방법
    - 전진선택법으로 변수 추가 시 예상되는 벌점 값과 이미 추가된 변수 제거 시 예상되는 벌점 값이 가장 작도록 만들어 가는 방법

---

**과적합**(과대적합)이란 모델이 학습 데이터를 과하게 학습하는 것을 의미한다.

학습 데이터에 과적합되면 학습 데이터에 너무 맞춰져서 새로운 데이터에 **일반화하기가 어렵다(일반화 성능이 낮아짐).**

반대로, 모델이 너무 단순해 학습 데이터조차 제대로 예측하지 못하는 경우를 **과소적합**이라 한다.

**정규화 선형회귀**는 회귀분석 시 과적합되면 계수의 크기도 과도하게 증가하는 경향을 막기위해 계수의 크기를 제한하는 것이다.

- 라쏘(Lasso, L1 규제) : **가중치들의 절댓값의 합**을 최소화하는 것을 제약조건으로 추가
    - 일부 불필요한 가중치 파라미터를 0으로 만들어 분서에서 아예 제외시킴
    - 몇 개의 의미있는 변수만 분석에 포함시키고 싶을 때 효과적
- 릿지(Ridge, L2 규제) : **가중치들의 제곱합**을 최소화하는 것을 제약조건으로 추가
    - 일부 가중치 파라미터를 제한하지만, **완전히 0으로는 만들지는 않고** 0에 가깝게 만든다.
    - 선형 모델의 일반화 성능을 개선할 수 있음
- 엘라스틱넷 : 라쏘와 릿지를 결합한 모델

---

**일반화 선형회귀**는 종속변수가 범주형 자료이거나 정규성을 만족하지 못할 경우 종속변수를 적절히 함수로 정의하고, 이 함수와 독립변수를 선형 결합하여 회귀분석을 실행하는 것이다.

일반화 선형회귀의 구성 요소

- 확률 요소 : 종속변수의 확률분포를 규정하는 성분
- 선형 예측자 : 종속변수의 기댓값을 정의하는 독립변수들 간의 선형 결합
- 연결함수 : 확률 요소와 선형예측자를 연결하는 함수

일반화 선형회귀 종류

- **로지스틱 회귀** : **종속변수가 범주형 변수**일 때 사용
- **포아송 회귀** : **특정 시간** 동안 발생한 사건의 건수에 대한 도수자료이며, 종속변수가 **정규분포를 따르지 않거나 등분산성을 만족하지 못할 경우**

---

**시계열 데이터**는 시간의 흐름대로 나열된 데이터로, **연속적인 일련의 관측치들이 서로 상관되어 있다**. 즉, 하나의 잔차항의 크기가 다른 이웃하는 잔차항의 크기와 서로 일정한 관련이 있는데, 이를 **자기 상관성**이라고 한다.

회쉬분석을 수행하기 위해서는 오차항이 서로 연관성이 없어야 한다. 즉, **오차항의 공분산이 0**이어야 한다.

자기분산성이 존재한다면 회귀분석이 아닌 시계열 분석이나 다른 분석방법을 수행해야한다.

**더빈-왓슨 검정**은 자기상관성이 존재하는지 검정하는 방법이다.

- 더빈 왓슨 검정 통계량 값이 2에 가까울 수록 자기상관성이 적다.
- 0에 가까우면 양의 상관관계, 4에 가까우면 음의 상관관계가 있다.

---

회귀분석의 평가지표

![https://miro.medium.com/v2/resize:fit:720/format:webp/1*rnSUCGFzYMAnXBn0IE3Czg.png](https://miro.medium.com/v2/resize:fit:720/format:webp/1*rnSUCGFzYMAnXBn0IE3Czg.png)

---

**다차원 척도법**은 객체들 사이에 유사성이나 비유사성을 측정하여 객체 간의 근접성을 시각화하는 통계기법이다.(군집분석과 유사)

- 데이터를 축소하거나 데이터들의 정보 속성을 파악하기 위해 활용된다.
- 개체의 실제 거리와 추정된 거리 사이의 적합도를 측정하기 위해 stress 척도를 사용한다.
    - stress 값이 낮을수록 적합도가 높다.
    
    ![https://postfiles.pstatic.net/MjAyMDA1MjhfMjYy/MDAxNTkwNjY5MzY0NDQy.-kjIgOIqb4HHrhHbhzkv8Na1km9QZiQp5GNOIYxou7Ug.HynT75eZLVOce5k6G1fW49T5h3zOt6uXeSAjIsAoAysg.PNG.shoutjoy/image.png?type=w773](https://postfiles.pstatic.net/MjAyMDA1MjhfMjYy/MDAxNTkwNjY5MzY0NDQy.-kjIgOIqb4HHrhHbhzkv8Na1km9QZiQp5GNOIYxou7Ug.HynT75eZLVOce5k6G1fW49T5h3zOt6uXeSAjIsAoAysg.PNG.shoutjoy/image.png?type=w773)
    

---

**주성분분석**(PCA)은 서로 상관성이 높은 변수들의 선형 결합으로 **새로운 변수(주성분)**을 만들어 기존 변수를 요약, 축소하는 분석방법이다.

주성분분석의 목적

- **변수를 축소하여 모형의 설명력을 높임**
- **다중공선성 문제 해결**

손실이 가장 작은, 즉 자료의 분산이 가장 큰 축을 찾아 새로운 변수로 만든다.

데이터를 가장 잘 표현할 수 있는 직교상의 데이터 벡터들을 찾아서 데이터를 압축한다.

고유값은 고유 벡터의 크기를 의미하며, 클수록 높은 설명력을 가진다.

- 고유값이 평균보다 작은 값을 갖는 주성분을 제거하는 것이 평균 고유값 방법이다.

---

scree plot : x축을 성분개수, y축을 고윳값으로 갖는 그래프로 주성분의 개수를 선택할 수 있다.

- 고윳값이 1근처의 값을 갖는 주성분분석의 수
- 그래프가 수평을 이루기 전 단계의 주성분 수

---

**시계열 분석**은 **일정 시간 간격**으로 기록된 자료들의 특성을 파악하고 예측하는 분석이다.

시계열 자료들은 자기상관성을 가지고 있다, 즉 인접자료들끼리 상호 연관성을 가진다.

**공분산**은 **두 개의 확률 변수의 선형관계**, 두개의 확률 변수의 흩어진 정도를 나타낸다.

- 시계열 자료의 자기상관성때문에 공분산이 중요하다.
- 시계열 자료들은 자기상관성을 가지기 때문에 공분산은 0이 아니다/

시계열 자료는 대부분 비정상성 자료인데, 시계열 분석을 위해서는 정상성 자료로 변환해야한다.

---

시계열 자료의 정상성 조건

- **일정한 평균** : 모든 시점에 대하여 평균이 일정해야 한다.
    - 차분을 통해 정상화 할 수 있다.
- **일정한 분산** : 모든 시점에 대해 분산이 일정해야 한다.
    - 자료 값에 지수나 로그를 취해 변환하여 정상화 할 수 있다.
- **시차에만 의존하는 공분산** : 공분산은 시차에만 의존하고, **특정 시점에 의존하지 않는다.**
    - t ~ t+s 시점의 공분산과 t-s ~ t 시점의 공분산은 같아야한다.

---

자기상관계수(ACF) : **시간의 흐름에 따른** 자기상관관계를 나타내는 것

부분자기상관계수(PACF) : 두 시계열 확률변수 간에 다른 시점의 확률 변수 영향력은 통제하고 상관관계만 보여줌

---

시계열 분석 기법

- **이동평균법** : 시계열 데이터에서 일정 기간별로 자료를 묶어 평균을 구함
    - 장기적인 추세를 파악하는데 효율적
    - 모든 자료가 동등한 가중치 → 최신 정보 중요도가 낮아짐
- **지수평활법**
    - **최근 데이터일수록 큰 가중치를 부여**
    - 자료 수가 많고 안정된 패턴을 보이면 품질이 높아짐
    - 중장기 예측에 주로 사용

시계열 모형

- **자기회귀모형(AR)** : t라는 시점에서의 값 y는 이전 시점들 n개에 의해서 설명될 수 있음
    - 이전 시점의 자료값들에 의한 선형 결합
- **이동평균모형(MA)** :  이전 시점의 백색잡음들의 선형결합
    - 항상 정상성을 만족
- **자기회귀누적이동평균모형(ARIMA)** : 차분이나 변환으로 정상화하여 비정상 시계열 자료를 다룰 수 있는 모형
- 분해 시계열
    - **추세요인**, **계절요인**, **순환요인**, **불규칙요인**으로 ****혼합된 시계열 데이터를 분석목적에 따라 특정 요인만 분리해서 분석하거나 제거